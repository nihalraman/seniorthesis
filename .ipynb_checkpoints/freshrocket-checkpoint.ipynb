{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d0961ce-22e5-4b90-a5fa-d41dc7d4f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd64dde-7936-4089-b1e0-180aaefe3b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get relative indices\n",
    "# manually entered via looking at https://raw.githubusercontent.com/google/mediapipe/a908d668c730da128dfa8d9f6bd25d519d006692/mediapipe/modules/face_geometry/data/canonical_face_model_uv_visualization.png\n",
    "lower = [76, 77, 90, 180, 85, 16, 315, 404, 320, 307]\n",
    "\n",
    "upper = [184, 74, 73, 72, 11, 302, 303, 304, 408, 306]\n",
    "\n",
    "u2 = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409]\n",
    "l2 = [291, 375, 321, 405, 314, 17, 84, 181, 91, 146]\n",
    "\n",
    "u3 = [57, 186, 92, 165, 167, 164, 393, 391, 322, 410]\n",
    "l3 = [287, 273, 335, 406, 313, 18, 83, 182, 106, 43]\n",
    "\n",
    "combo_indices = lower + upper + u2 + l2 + u3 + l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "241d9b2c-3870-4231-8933-d7cee70ae879",
   "metadata": {},
   "outputs": [],
   "source": [
    "opath = \"/Users/nraman/Documents/thesis_videos/\"\n",
    "# make sure to get \n",
    "subfolders = [i for i in os.listdir(opath) if \".mp4\" not in i and \".DS_Store\" not in i and \".MOV\" not in i]\n",
    "\n",
    "def find_pointfolder(subfolder, path = \"/Users/nraman/Documents/thesis_videos/\"):\n",
    "    cur_path = f\"{path}{subfolder}\"\n",
    "    # get names of files within the subfolder\n",
    "    subfiles = os.listdir(f\"{path}{subfolder}\")\n",
    "    nps = [i for i in subfiles if \".npy\" in i]\n",
    "    \n",
    "    if(len(nps) > 1):\n",
    "        return(\"Error: Multiple np arrays saved in the folder\")\n",
    "    else:\n",
    "        array = np.load(f\"{cur_path}/{nps[0]}\")\n",
    "        array = array[:, combo_indices]\n",
    "        return(array.reshape(array.shape[0], len(combo_indices)*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea76c5bc-56bc-4db2-8308-3ab260e695da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_folders = [i for i in subfolders if \"ground\" in i]\n",
    "speak_folders = [i for i in subfolders if \"ground\" not in i]\n",
    "\n",
    "ground_data = []\n",
    "speak_data = []\n",
    "\n",
    "for g in ground_folders:\n",
    "    ground_data.append(find_pointfolder(g))\n",
    "\n",
    "for s in speak_folders:\n",
    "    speak_data.append(find_pointfolder(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3fbc6c5-24d0-490a-8eb9-2d5a8e61a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each input is list of arrays (each 2d, of dimension #timepoints x #points*2)--ground corresponds to no speech\n",
    "# get dataframe of dimension #samples x #features\n",
    "def timeseries_df(groundlist, speaklist, window = 12, num_features = len(combo_indices)*2):\n",
    "    sz = len(groundlist) + len(speaklist)\n",
    "    numspeak = len(speak_data)\n",
    "\n",
    "    df = pd.DataFrame(np.zeros([sz, num_features])).astype(object)\n",
    "\n",
    "    for j in range(sz):\n",
    "        for a in range(len(combo_indices)*2):\n",
    "            if(j < numspeak):\n",
    "                cur = speaklist[j][:, a]\n",
    "                # use last 12 frames since Nandita tended to say words towards the end of videos\n",
    "                df.iloc[j, a] = pd.Series(cur[-window:])\n",
    "            else:\n",
    "                it = j - numspeak\n",
    "                cur = groundlist[it][:, a]\n",
    "                df.iloc[j, a] = pd.Series(cur[-window:])\n",
    "    \n",
    "    true = np.concatenate([np.ones(numspeak), np.zeros(sz - numspeak)])\n",
    "    \n",
    "    return df, true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cec6552-cfff-4bca-86d2-fd259ec70a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata, alltrue = timeseries_df(ground_data, speak_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7b6ea12-02eb-4e49-8ff1-2faf91a5c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(alldata, alltrue, test_size = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "445e9a18-d280-4144-8686-95cb1adbc013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train Rocket embedding\n",
    "# rocket = Rocket()\n",
    "# rocket.fit(X_train)\n",
    "# X_train_transform = rocket.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e63a9154-e337-40b3-b8f3-bd07ed7eaea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train logistic regression classifier\n",
    "# classifier = LDA()\n",
    "# classifier.fit(X_train_transform, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7308fab3-d7c7-4dbe-bd35-5061d8d58ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_transform = rocket.transform(X_test)\n",
    "# print(classifier.score(X_test_transform, y_test))\n",
    "# print(classifier.predict(X_test_transform))\n",
    "# print(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f64d354-f637-4b7c-8bbc-5be52d2c901f",
   "metadata": {},
   "source": [
    "### STRANGE NOTE: \n",
    "When timeseries_df looks like the code below, I get classifier accuracies around 60%. However, when I change to cur[:window], I get around 90% accuracy!\n",
    "         "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e65fe148-1246-4340-9567-264c2441784d",
   "metadata": {},
   "source": [
    "it = j - numspeak\n",
    "cur = groundlist[it][:, a]\n",
    "df.iloc[j, a] = pd.Series(cur[-window:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90f44307-3408-4f95-a30d-82ae7f2851d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:08,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X = alldata, y = alltrue)\n",
    "\n",
    "preds = []\n",
    "actual = []\n",
    "\n",
    "for train_index, test_index in tqdm(kf.split(alldata)):\n",
    "    X_train, X_test = alldata.iloc[train_index,:], alldata.iloc[test_index,:]\n",
    "    y_train, y_test = alltrue[train_index], alltrue[test_index]\n",
    "    \n",
    "    rocket = Rocket()\n",
    "    rocket.fit(X_train)\n",
    "    X_train_transform = rocket.transform(X_train)\n",
    "    \n",
    "    model = LR(max_iter = 2000)\n",
    "    model.fit(X_train_transform, y_train)\n",
    "    \n",
    "    pred_values = model.predict(rocket.transform(X_test))\n",
    "    preds.append([int(i) for i in pred_values])\n",
    "    actual.append([int(i) for i in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d8b7cc6-eb91-4013-a23a-a3685c770725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-Speech       0.82      0.85      0.84        27\n",
      "      Speech       0.93      0.91      0.92        58\n",
      "\n",
      "    accuracy                           0.89        85\n",
      "   macro avg       0.88      0.88      0.88        85\n",
      "weighted avg       0.90      0.89      0.89        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "allpreds = np.concatenate(preds)\n",
    "allactual = np.concatenate(actual)\n",
    "\n",
    "print(classification_report(allactual, allpreds, target_names=[\"Non-Speech\", \"Speech\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290b0ec-7b7f-43df-bd3b-d0be5becfdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd5e44-b598-49f2-9dbb-f4af05af064a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
