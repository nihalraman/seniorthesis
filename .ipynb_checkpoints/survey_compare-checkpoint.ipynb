{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f74b9e3d-361f-4420-89e9-c00a5b80c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.model_selection import StratifiedKFold as KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import classification_report\n",
    "from sktime.transformations.panel.rocket import MiniRocketMultivariate as minirocket\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegressionCV as LRCV\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5f05ff-32c5-4beb-bab7-3ab5230849c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get relative indices\n",
    "# manually entered via looking at\n",
    "#https://raw.githubusercontent.com/google/mediapipe/a908d668c730da128dfa8d9f6bd25d519d006692/mediapipe/modules\n",
    "#/face_geometry/data/canonical_face_model_uv_visualization.png\n",
    "\n",
    "lower = [76, 77, 90, 180, 85, 16, 315, 404, 320, 307]\n",
    "\n",
    "upper = [184, 74, 73, 72, 11, 302, 303, 304, 408, 306]\n",
    "\n",
    "u2 = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409]\n",
    "l2 = [291, 375, 321, 405, 314, 17, 84, 181, 91, 146]\n",
    "\n",
    "u3 = [57, 186, 92, 165, 167, 164, 393, 391, 322, 410]\n",
    "l3 = [287, 273, 335, 406, 313, 18, 83, 182, 106, 43]\n",
    "\n",
    "combo_indices = lower + upper + u2 + l2 + u3 + l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b83282b-4184-4d95-b405-131da1cb17df",
   "metadata": {},
   "outputs": [],
   "source": [
    "opath = \"/Users/nraman/Documents/thesis_videos/\"\n",
    "# make sure to get \n",
    "subfolders_o = [i for i in os.listdir(opath) if \".mp4\" not in i and \".DS_Store\" not in i and \".MOV\" not in i and \":\" in i]\n",
    "def find_pointfolder(subfolder, path = \"/Users/nraman/Documents/thesis_videos/\"):\n",
    "    cur_path = f\"{path}{subfolder}\"\n",
    "    # get names of files within the subfolder\n",
    "    subfiles = os.listdir(f\"{path}{subfolder}\")\n",
    "    nps = [i for i in subfiles if \".npy\" in i]\n",
    "    \n",
    "    if(len(nps) == 1):\n",
    "        array = np.load(f\"{cur_path}/{nps[0]}\")\n",
    "        array = array[:, combo_indices]\n",
    "        return(array.reshape(array.shape[0], len(combo_indices)*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f074c7-e4f9-4c41-b07e-9cdd7bcaffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_vids = [\"ground_2022-01-30 13:10:43.042718\", \"speech_2022-01-30 13:11:13.294959\", \"test_speech_2022-01-30 13:17:21.709320\", \"ground_2022-01-30 13:14:52.838457\", \"toughspeech_2022-01-21 17:16:31.471513\", \"speech_2022-01-30 13:16:03.437350\", \"ground_2022-01-30 13:12:36.560644\", \"speech_2022-01-21 17:16:49.125882\", \"speech_2022-01-30 13:16:23.665258\", \"test_ground_2022-01-30 13:17:11.646731\", \"speech_2022-01-21 17:15:30.844708\", \"speech_2022-01-21 17:15:33.359457\", \"ground_2022-01-30 13:16:43.888130\", \"test_speech_2022-01-30 13:17:31.804069\", \"test_speech_2022-01-30 13:16:48.923784\", \"ground_2022-01-30 13:16:38.857619\", \"test_speech_2022-01-30 13:17:04.051593\", \"ground_2022-01-30 13:16:36.326310\", \"test_speech_2022-01-30 13:17:19.207557\", \"ground_2022-01-30 13:15:00.402267\", \"ground_2022-01-30 13:15:02.930923\", \"test_speech_2022-01-30 13:17:06.582569\", \"ground_2022-01-30 13:15:13.027508\", \"test_speech_2022-01-30 13:17:21.709320\", \"ground_2022-01-30 13:15:15.528437\", \"test_speech_2022-01-30 13:17:16.677879\", \"test_speech_2022-01-30 13:17:09.114865\", \"test_speech_2022-01-30 13:17:01.518291\", \"ground_2022-01-30 13:15:18.057479\", \"ground_2022-01-30 13:15:20.557555\", \"ground_2022-01-30 13:15:23.090369\", \"ground_2022-01-30 13:15:25.623818\", \"ground_2022-01-30 13:15:43.281139\", \"ground_2022-01-30 13:16:28.733014\", \"test_speech_2022-01-30 13:16:58.982645\", \"ground_2022-01-30 13:16:31.263864\", \"test_speech_2022-01-30 13:16:56.453104\", \"ground_2022-01-30 13:16:33.794845\", \"test_speech_2022-01-30 13:17:26.738585\", \"test_speech_2022-01-30 13:16:53.952632\", \"test_speech_2022-01-30 13:17:29.274213\", \"ground_2022-01-29 14:30:45.524129\", \"ground_2022-01-29 14:30:50.555178\", \"ground_2022-01-29 14:30:53.087316\", \"speech_2022-01-29 14:29:39.816558\", \"ground_2022-01-29 14:30:55.618885\", \"speech_2022-01-29 14:29:42.350774\", \"speech_2022-01-29 14:29:37.316120\", \"speech_2022-01-29 14:29:47.412646\", \"ground_2022-01-29 14:30:58.152935\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "175e826a-aee4-41f0-a185-3863d3114ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_folders = [i for i in survey_vids if i in subfolders_o]\n",
    "subfolders = [i for i in subfolders_o if i not in survey_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71c98b9-f4a9-4193-8470-8d99ba98b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_folders = [i for i in subfolders if \"ground\" in i]\n",
    "speak_folders = [i for i in subfolders if \"ground\" not in i]\n",
    "bad_ones = []\n",
    "\n",
    "ground_data = []\n",
    "speak_data = []\n",
    "\n",
    "for s in speak_folders:\n",
    "    data = find_pointfolder(s)\n",
    "    #if(len(data) < 40):\n",
    "    if(type(data) == np.ndarray):\n",
    "        speak_data.append(data)\n",
    "    else:\n",
    "        bad_ones.append(s)\n",
    "\n",
    "s_lengths = [s.shape[0] for s in speak_data]\n",
    "g_lengths = []\n",
    "\n",
    "for g in ground_folders:\n",
    "    ar_init = find_pointfolder(g)\n",
    "#     num_instances = ar_init.shape[0]\n",
    "#     g_lengths.append(num_instances)\n",
    "#     choice = np.random.randint(15, 30)\n",
    "    \n",
    "#     if(num_instances > 700):\n",
    "#         splits = 2\n",
    "#     else:\n",
    "#         splits = 1\n",
    "    \n",
    "    #ground_data.extend(np.array_split(ar_init, splits))\n",
    "    if(type(ar_init) == np.ndarray):\n",
    "        ground_data.append(ar_init)\n",
    "    else:\n",
    "        bad_ones.append(g)\n",
    "        \n",
    "s_lengths = [s.shape[0] for s in speak_data]\n",
    "g_lengths = [s.shape[0] for s in ground_data]\n",
    "maxlen = np.max(s_lengths + g_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90107e47-f0d9-4de5-857d-aeeeb7e920de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each input is list of arrays (each 2d, of dimension #timepoints x #points*2)--ground corresponds to no speech\n",
    "# get dataframe of dimension #samples x #features\n",
    "def timeseries_df(groundlist, speaklist, num_features = len(combo_indices)*2, const = 0, pd_mode = True):\n",
    "    sz = len(groundlist) + len(speaklist)\n",
    "    numspeak = len(speaklist)\n",
    "    \n",
    "    if(pd_mode == True):\n",
    "        df = pd.DataFrame(np.zeros([sz, num_features])).astype(object)\n",
    "    else:\n",
    "        df = np.zeros((sz, num_features, maxlen))\n",
    "    \n",
    "    for j in range(int(sz)):\n",
    "        for a in range(len(combo_indices)*2):\n",
    "            if(j < numspeak):\n",
    "                cur = speaklist[j][:, a]\n",
    "            elif (j >= numspeak):\n",
    "                it = j - numspeak\n",
    "                cur = groundlist[it][:, a]\n",
    "            \n",
    "            if(pd_mode == True):\n",
    "                df.iloc[j, a] = np.pad(cur, (0, maxlen - len(cur)), constant_values = (const))\n",
    "            else:\n",
    "                df[a, j] = np.pad(cur, (0, maxlen - len(cur)), constant_values = (const))\n",
    "    \n",
    "    true = np.concatenate([np.ones(numspeak), np.zeros(sz - numspeak)])\n",
    "    \n",
    "    return df, true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c71116-f971-45d0-9809-a495e9d41b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata, alltrue = timeseries_df(ground_data, speak_data)\n",
    "rocket = minirocket(num_kernels = 10000, n_jobs = -1, random_state = 99)\n",
    "rocket.fit(alldata)\n",
    "X_train = rocket.transform(alldata)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_transform = scaler.transform(X_train)\n",
    "lda = LDA()\n",
    "lda.fit(X_train_transform, alltrue)\n",
    "model = GaussianNB()\n",
    "model.fit(lda.transform(X_train_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb31d07-b1b0-40fd-86cd-316ba027fc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltrue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1406c2c9-4a37-4876-bcb2-a6ff121cd8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_survey = [i for i in survey_folders if \"ground\" in i]\n",
    "speak_survey = [i for i in survey_folders if \"ground\" not in i]\n",
    "\n",
    "s_ground_data = []\n",
    "s_speak_data = []\n",
    "\n",
    "for s in speak_survey:\n",
    "    data = find_pointfolder(s)\n",
    "    #if(len(data) < 40):\n",
    "    if(type(data) == np.ndarray):\n",
    "        s_speak_data.append(data)\n",
    "\n",
    "for g in ground_survey:\n",
    "    ar_init = find_pointfolder(g)\n",
    "#     num_instances = ar_init.shape[0]\n",
    "#     g_lengths.append(num_instances)\n",
    "#     choice = np.random.randint(15, 30)\n",
    "    \n",
    "#     if(num_instances > 700):\n",
    "#         splits = 2\n",
    "#     else:\n",
    "#         splits = 1\n",
    "    \n",
    "    #ground_data.extend(np.array_split(ar_init, splits))\n",
    "    if(type(ar_init) == np.ndarray):\n",
    "        s_ground_data.append(ar_init)\n",
    "        \n",
    "s_s_lengths = [s.shape[0] for s in s_speak_data]\n",
    "s_g_lengths = [s.shape[0] for s in s_ground_data]\n",
    "maxlen = np.max(s_s_lengths + s_g_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4594524-1201-4566-8caa-6267cae7dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_X, survey_y = timeseries_df(s_ground_data, s_speak_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a83953f-964c-4eb5-984e-e220593bed26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(lda.transform(scaler.transform(rocket.transform(survey_X))), survey_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50ca124-960c-4b9b-9cc4-db824a084677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30137c0d-a574-4468-ab29-69929ae16c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "def",
   "language": "python",
   "name": "def"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
