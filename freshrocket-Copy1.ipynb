{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d0961ce-22e5-4b90-a5fa-d41dc7d4f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.model_selection import StratifiedKFold as KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import classification_report\n",
    "from sktime.transformations.panel.rocket import MiniRocketMultivariate as minirocket\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegressionCV as LRCV\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd64dde-7936-4089-b1e0-180aaefe3b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get relative indices\n",
    "# manually entered via looking at\n",
    "#https://raw.githubusercontent.com/google/mediapipe/a908d668c730da128dfa8d9f6bd25d519d006692/mediapipe/modules\n",
    "#/face_geometry/data/canonical_face_model_uv_visualization.png\n",
    "\n",
    "lower = [76, 77, 90, 180, 85, 16, 315, 404, 320, 307]\n",
    "\n",
    "upper = [184, 74, 73, 72, 11, 302, 303, 304, 408, 306]\n",
    "\n",
    "u2 = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409]\n",
    "l2 = [291, 375, 321, 405, 314, 17, 84, 181, 91, 146]\n",
    "\n",
    "u3 = [57, 186, 92, 165, 167, 164, 393, 391, 322, 410]\n",
    "l3 = [287, 273, 335, 406, 313, 18, 83, 182, 106, 43]\n",
    "\n",
    "combo_indices = lower + upper + u2 + l2 + u3 + l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "241d9b2c-3870-4231-8933-d7cee70ae879",
   "metadata": {},
   "outputs": [],
   "source": [
    "opath = \"/Users/nraman/Documents/thesis_videos/\"\n",
    "# make sure to get \n",
    "subfolders = [i for i in os.listdir(opath) if \".mp4\" not in i and \".DS_Store\" not in i and \".MOV\" not in i and \"test\" not in i]\n",
    "\n",
    "def find_pointfolder(subfolder, path = \"/Users/nraman/Documents/thesis_videos/\"):\n",
    "    cur_path = f\"{path}{subfolder}\"\n",
    "    # get names of files within the subfolder\n",
    "    subfiles = os.listdir(f\"{path}{subfolder}\")\n",
    "    nps = [i for i in subfiles if \".npy\" in i]\n",
    "    \n",
    "    if(len(nps) == 1):\n",
    "        array = np.load(f\"{cur_path}/{nps[0]}\")\n",
    "        array = array[:, combo_indices]\n",
    "        return(array.reshape(array.shape[0], len(combo_indices)*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea76c5bc-56bc-4db2-8308-3ab260e695da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_folders = [i for i in subfolders if \"ground\" in i]\n",
    "speak_folders = [i for i in subfolders if \"ground\" not in i]\n",
    "bad_ones = []\n",
    "\n",
    "ground_data = []\n",
    "speak_data = []\n",
    "\n",
    "for s in speak_folders:\n",
    "    data = find_pointfolder(s)\n",
    "    if(type(data) == np.ndarray):\n",
    "        speak_data.append(data)\n",
    "    else:\n",
    "        bad_ones.append(s)\n",
    "\n",
    "\n",
    "\n",
    "for g in ground_folders:\n",
    "    ar_init = find_pointfolder(g)\n",
    "    if(type(ar_init) == np.ndarray):\n",
    "        ground_data.append(ar_init)\n",
    "    else:\n",
    "        bad_ones.append(g)\n",
    "        \n",
    "s_lengths = [s.shape[0] for s in speak_data]\n",
    "g_lengths = [s.shape[0] for s in ground_data]\n",
    "trainmax = np.max(s_lengths + g_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "477e360e-bf4e-417c-8fe0-17c22ed4f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfolders = [i for i in os.listdir(opath) if \".mp4\" not in i and \".DS_Store\" not in i and \".MOV\" not in i and \"test\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f5b343e-82d8-4f51-bf6d-17d415ec76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testground = [i for i in testfolders if \"ground\" in i]\n",
    "testspeak = [i for i in testfolders if \"ground\" not in i]\n",
    "test_bad = []\n",
    "\n",
    "test_ground_data = []\n",
    "test_speak_data = []\n",
    "\n",
    "for s in testspeak:\n",
    "    data = find_pointfolder(s)\n",
    "    if(type(data) == np.ndarray):\n",
    "        test_speak_data.append(data)\n",
    "    else:\n",
    "        test_bad.append(s)\n",
    "\n",
    "s_lengths = [s.shape[0] for s in test_speak_data]\n",
    "\n",
    "for g in testground:\n",
    "    ar_init = find_pointfolder(g)\n",
    "    if(type(ar_init) == np.ndarray):\n",
    "        test_ground_data.append(ar_init)\n",
    "    else:\n",
    "        test_bad.append(g)\n",
    "        \n",
    "ts_lengths = [s.shape[0] for s in test_speak_data]\n",
    "tg_lengths = [s.shape[0] for s in test_ground_data]\n",
    "testmax = np.max(ts_lengths + tg_lengths)\n",
    "\n",
    "maxlen = max([trainmax, testmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324358d8-d94d-4dd9-923b-86ef16535b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3fbc6c5-24d0-490a-8eb9-2d5a8e61a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each input is list of arrays (each 2d, of dimension #timepoints x #points*2)--ground corresponds to no speech\n",
    "# get dataframe of dimension #samples x #features\n",
    "def timeseries_df(groundlist, speaklist, num_features = len(combo_indices)*2, const = 0, pd_mode = True):\n",
    "    sz = len(groundlist) + len(speaklist)\n",
    "    numspeak = len(speaklist)\n",
    "    \n",
    "    if(pd_mode == True):\n",
    "        df = pd.DataFrame(np.zeros([sz, num_features])).astype(object)\n",
    "    else:\n",
    "        df = np.zeros((sz, num_features, maxlen))\n",
    "    \n",
    "    for j in range(int(sz)):\n",
    "        for a in range(len(combo_indices)*2):\n",
    "            if(j < numspeak):\n",
    "                cur = speaklist[j][:, a]\n",
    "            elif (j >= numspeak):\n",
    "                it = j - numspeak\n",
    "                cur = groundlist[it][:, a]\n",
    "            \n",
    "            if(pd_mode == True):\n",
    "                df.iloc[j, a] = np.pad(cur, (0, maxlen - len(cur)), constant_values = (const))\n",
    "            else:\n",
    "                df[a, j] = np.pad(cur, (0, maxlen - len(cur)), constant_values = (const))\n",
    "    \n",
    "    true = np.concatenate([np.ones(numspeak), np.zeros(sz - numspeak)])\n",
    "    \n",
    "    return df, true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cec6552-cfff-4bca-86d2-fd259ec70a8c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_X, train_y = timeseries_df(ground_data, speak_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "445e9a18-d280-4144-8686-95cb1adbc013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train Rocket embedding\n",
    "rocket = minirocket()\n",
    "rocket.fit(train_X)\n",
    "inter = rocket.transform(train_X)\n",
    "\n",
    "scaler = StandardScaler().fit(inter)\n",
    "X_train_transform = scaler.transform(inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e63a9154-e337-40b3-b8f3-bd07ed7eaea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight={0: 0.01, 1: 1}, max_iter=10000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # train logistic regression classifier\n",
    "classifier = LR(max_iter = 10000, class_weight = {0:0.01, 1:1})#SVC(C = 1e-1)\n",
    "classifier.fit(X_train_transform, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d8b7cc6-eb91-4013-a23a-a3685c770725",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testy = timeseries_df(test_ground_data, test_speak_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf371b6-df58-4d9a-84c0-33aef29ea673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5290b0ec-7b7f-43df-bd3b-d0be5becfdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier.predict(scaler.transform(rocket.transform(testX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcdcdd8b-8da0-4354-a9ce-8cc82321c4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[ 9  4]\n",
      " [ 4 37]]\n",
      "False rejection rate: 0.07407407407407407\n"
     ]
    }
   ],
   "source": [
    "c = metrics.confusion_matrix(testy, preds)\n",
    "print(\"Confusion Matrix: \" + str(c))\n",
    "print(\"False rejection rate: \" + str(c[1, 0]/np.sum(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f456c29-4b9f-4ff5-b098-4ede40ae3c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.69      0.69        13\n",
      "         1.0       0.90      0.90      0.90        41\n",
      "\n",
      "    accuracy                           0.85        54\n",
      "   macro avg       0.80      0.80      0.80        54\n",
      "weighted avg       0.85      0.85      0.85        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testy, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61fcd6e-ce3f-4761-baa2-7a4dc04492c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b7b53-3c06-46fc-b18c-0261e43489b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
